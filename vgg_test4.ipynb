{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras version:  2.4.0\n",
      "tensorflow version:  2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "img_height=224\n",
    "img_width=291\n",
    "batch_size=32\n",
    "\n",
    "print(\"keras version: \", keras.__version__)\n",
    "print(\"tensorflow version: \" ,tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 280 files belonging to 2 classes.\n",
      "Using 224 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds=tf.keras.preprocessing.image_dataset_from_directory(\n",
    "            '../data', labels='inferred', label_mode='int',\n",
    "            validation_split=0.2, subset='training', seed=123,\n",
    "#             color_mode='grayscale', \n",
    "            image_size=(img_height, img_width),\n",
    "            batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 280 files belonging to 2 classes.\n",
      "Using 56 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds=tf.keras.preprocessing.image_dataset_from_directory(\n",
    "            '../data', labels='inferred', label_mode='int',\n",
    "            validation_split=0.2, subset='validation', seed=123,\n",
    "#             color_mode='grayscale', \n",
    "            image_size=(img_height, img_width),\n",
    "            batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 291, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 224, 291, 3)       0         \n",
      "_________________________________________________________________\n",
      "normalization (Normalization (None, 224, 291, 3)       7         \n",
      "_________________________________________________________________\n",
      "xception (Functional)        (None, 7, 9, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 20,863,536\n",
      "Trainable params: 2,049\n",
      "Non-trainable params: 20,861,487\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = keras.applications.Xception(weights='imagenet', \n",
    "                                        input_shape=(img_height,img_width,3),\n",
    "                                        include_top=False)\n",
    "# base_model = keras.applications.VGG16(weights='imagenet', \n",
    "#                                         input_shape=(img_height,img_width,3),\n",
    "#                                         include_top=False)\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs=keras.Input(shape=(img_height,img_width,3))\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "                    [\n",
    "                        layers.experimental.preprocessing.RandomFlip(\"horizontal\",\n",
    "                                                    input_shape=(img_height,img_width,3)),\n",
    "                        layers.experimental.preprocessing.RandomFlip(\"vertical\"),\n",
    "              #         layers.experimental.preprocessing.RandomRotation(0.1, input_shape=(img_height,img_width,1))\n",
    "                        layers.experimental.preprocessing.RandomRotation(0.1)\n",
    "                   ]\n",
    ")\n",
    "\n",
    "x = data_augmentation(inputs)\n",
    "norm_layer = keras.layers.experimental.preprocessing.Normalization()\n",
    "mean =np.array([127.5]*3)\n",
    "var = mean**2\n",
    "\n",
    "x = norm_layer(x)\n",
    "norm_layer.set_weights([mean,var])\n",
    "\n",
    "x = base_model(x,training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "outputs = keras.layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 13s 2s/step - loss: 0.6872 - binary_accuracy: 0.5268 - val_loss: 0.6065 - val_binary_accuracy: 0.9643\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 4s 529ms/step - loss: 0.5201 - binary_accuracy: 0.7857 - val_loss: 0.4879 - val_binary_accuracy: 0.9821\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 4s 507ms/step - loss: 0.4070 - binary_accuracy: 0.8795 - val_loss: 0.3714 - val_binary_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 4s 522ms/step - loss: 0.3198 - binary_accuracy: 0.9152 - val_loss: 0.3067 - val_binary_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 4s 518ms/step - loss: 0.2615 - binary_accuracy: 0.9732 - val_loss: 0.2711 - val_binary_accuracy: 0.9821\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 4s 527ms/step - loss: 0.2134 - binary_accuracy: 0.9509 - val_loss: 0.2218 - val_binary_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 4s 531ms/step - loss: 0.1920 - binary_accuracy: 0.9598 - val_loss: 0.1829 - val_binary_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 4s 526ms/step - loss: 0.1641 - binary_accuracy: 0.9598 - val_loss: 0.2001 - val_binary_accuracy: 0.9821\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 4s 536ms/step - loss: 0.1672 - binary_accuracy: 0.9777 - val_loss: 0.1962 - val_binary_accuracy: 0.9821\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 4s 536ms/step - loss: 0.1356 - binary_accuracy: 0.9866 - val_loss: 0.1604 - val_binary_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 4s 537ms/step - loss: 0.1174 - binary_accuracy: 0.9777 - val_loss: 0.1476 - val_binary_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 4s 539ms/step - loss: 0.1143 - binary_accuracy: 0.9821 - val_loss: 0.1390 - val_binary_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 4s 523ms/step - loss: 0.1089 - binary_accuracy: 0.9821 - val_loss: 0.1351 - val_binary_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 4s 519ms/step - loss: 0.1149 - binary_accuracy: 0.9732 - val_loss: 0.1207 - val_binary_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 4s 528ms/step - loss: 0.1088 - binary_accuracy: 0.9821 - val_loss: 0.1189 - val_binary_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 4s 532ms/step - loss: 0.0952 - binary_accuracy: 0.9821 - val_loss: 0.1140 - val_binary_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 4s 527ms/step - loss: 0.0939 - binary_accuracy: 0.9866 - val_loss: 0.1122 - val_binary_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 4s 512ms/step - loss: 0.0848 - binary_accuracy: 0.9866 - val_loss: 0.1050 - val_binary_accuracy: 1.0000\n",
      "Epoch 19/20\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "             loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "             metrics=[keras.metrics.BinaryAccuracy()])\n",
    "\n",
    "epochs=20\n",
    "model.fit(train_ds, epochs=epochs, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 224, 291, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 224, 291, 3)       0         \n",
      "_________________________________________________________________\n",
      "normalization (Normalization (None, 224, 291, 3)       7         \n",
      "_________________________________________________________________\n",
      "vgg16 (Functional)           (None, 7, 9, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 14,715,208\n",
      "Trainable params: 14,715,201\n",
      "Non-trainable params: 7\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/7 [=======>......................] - ETA: 0s - loss: 0.5294 - binary_accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0888s vs `on_train_batch_end` time: 0.1726s). Check your callbacks.\n",
      "7/7 [==============================] - 5s 681ms/step - loss: 0.4209 - binary_accuracy: 0.8705 - val_loss: 0.2461 - val_binary_accuracy: 0.9464\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 4s 620ms/step - loss: 0.2364 - binary_accuracy: 0.9286 - val_loss: 0.1345 - val_binary_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 5s 654ms/step - loss: 0.1247 - binary_accuracy: 0.9509 - val_loss: 0.2117 - val_binary_accuracy: 0.9821\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 4s 626ms/step - loss: 0.0948 - binary_accuracy: 0.9688 - val_loss: 0.0268 - val_binary_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 5s 672ms/step - loss: 0.0503 - binary_accuracy: 0.9821 - val_loss: 0.0914 - val_binary_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 5s 648ms/step - loss: 0.0521 - binary_accuracy: 0.9821 - val_loss: 0.0358 - val_binary_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 4s 632ms/step - loss: 0.0297 - binary_accuracy: 0.9911 - val_loss: 0.0400 - val_binary_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 5s 668ms/step - loss: 0.0207 - binary_accuracy: 0.9955 - val_loss: 0.0152 - val_binary_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 5s 674ms/step - loss: 0.0262 - binary_accuracy: 0.9955 - val_loss: 0.0433 - val_binary_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 5s 689ms/step - loss: 0.0119 - binary_accuracy: 0.9955 - val_loss: 0.0199 - val_binary_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 4s 621ms/step - loss: 0.0166 - binary_accuracy: 0.9955 - val_loss: 0.0673 - val_binary_accuracy: 0.9821\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 5s 682ms/step - loss: 0.0188 - binary_accuracy: 0.9955 - val_loss: 0.0057 - val_binary_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 5s 686ms/step - loss: 0.0167 - binary_accuracy: 0.9866 - val_loss: 0.1963 - val_binary_accuracy: 0.9464\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 5s 669ms/step - loss: 0.0138 - binary_accuracy: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 5s 678ms/step - loss: 0.0175 - binary_accuracy: 0.9955 - val_loss: 0.1369 - val_binary_accuracy: 0.9464\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 5s 678ms/step - loss: 0.0220 - binary_accuracy: 0.9955 - val_loss: 0.0047 - val_binary_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 5s 674ms/step - loss: 0.0206 - binary_accuracy: 0.9955 - val_loss: 0.1318 - val_binary_accuracy: 0.9464\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 5s 686ms/step - loss: 0.0103 - binary_accuracy: 0.9955 - val_loss: 0.0216 - val_binary_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 5s 678ms/step - loss: 0.0090 - binary_accuracy: 0.9955 - val_loss: 0.1222 - val_binary_accuracy: 0.9464\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 5s 669ms/step - loss: 0.0081 - binary_accuracy: 0.9955 - val_loss: 0.0163 - val_binary_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b15c8de6d50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.trainable=True\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-5), loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "             metrics=[keras.metrics.BinaryAccuracy()])\n",
    "\n",
    "epochs=20\n",
    "model.fit(train_ds, epochs=epochs, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
